{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "185b27b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de82ebb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789ae890",
   "metadata": {},
   "source": [
    "# 1)First Data Change into LowerCase:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1615141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"review\"] = df[\"review\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38a4f143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production. <br /><br />the...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically there's a family where a little boy ...  negative\n",
       "4  petter mattei's \"love in the time of money\" is...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0651d1b1",
   "metadata": {},
   "source": [
    "# 2)Remove HTML Tags:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ba33553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_html_tags(text):\n",
    "    pattern = re.compile('<.*?>')\n",
    "    return pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5f36f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f38331a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production. the filming tec...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically there's a family where a little boy ...  negative\n",
       "4  petter mattei's \"love in the time of money\" is...  positive"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae2e0c0",
   "metadata": {},
   "source": [
    "# 3)Remove URLS:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "649ab54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ace96d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"Hello https://www.google.com/aaa\"\n",
    "text2 = \"Hello http://www.google.com/aaa\"\n",
    "text3 = \"Hello www.google.com/aaa\"\n",
    "text4 = \"Hello https://www.google.com/aaa/bbb this link\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7cf39c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_urls(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37077024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_urls(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "701d27fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_urls(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45aac79a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello  this link'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_urls(text4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81d0407",
   "metadata": {},
   "source": [
    "# 4)Remove Punctuation(Symbols):-"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6960d4d",
   "metadata": {},
   "source": [
    "i)Built Logic:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12d1d1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string,time\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70d9f202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude = string.punctuation\n",
    "exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ceed1af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    for char in exclude:\n",
    "        text = text.replace(char,'')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9591d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"string^&*. With. punctuation!!@#\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c45f051b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string With punctuation\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(remove_punctuation(text))\n",
    "time1 = time.time() - start\n",
    "print(time1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f7d8f69",
   "metadata": {},
   "source": [
    "ii)Default Function:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ab480cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('','',exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "456d6640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string With punctuation\n",
      "0.0006761550903320312\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(def_remove_punctuation(text))\n",
    "time2 = time.time() - start\n",
    "print(time2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20ed595",
   "metadata": {},
   "source": [
    "# 5)Chat Word Manage:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d027228",
   "metadata": {},
   "outputs": [],
   "source": [
    "##https://github.com/rishabhverma17/sms_slang_translator/blob/master/slang.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6976e8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_words = {\n",
    "'AFAIK':'As Far As I Know',\n",
    "'AFK':'Away From Keyboard',\n",
    "'ASAP':'As Soon As Possible',\n",
    "'ATK':'At The Keyboard',\n",
    "'ATM':'At The Moment',\n",
    "'A3':'Anytime, Anywhere, Anyplace',\n",
    "'BAK':'Back At Keyboard',\n",
    "'BBL':'Be Back Later',\n",
    "'BBS':'Be Back Soon',\n",
    "'BFN':'Bye For Now',\n",
    "'B4N':'Bye For Now',\n",
    "'BRB':'Be Right Back',\n",
    "'BRT':'Be Right There',\n",
    "'BTW':'By The Way',\n",
    "'B4':'Before',\n",
    "'B4N':'Bye For Now',\n",
    "'CU':'See You',\n",
    "'CUL8R':'See You Later',\n",
    "'CYA':'See You',\n",
    "'FAQ':'Frequently Asked Questions',\n",
    "'FC':'Fingers Crossed',\n",
    "'FWIW':'For What Its Worth',\n",
    "'FYI':'For Your Information',\n",
    "'GAL':'Get A Life',\n",
    "'GG':'Good Game',\n",
    "'GN':'Good Night',\n",
    "'GMTA':'Great Minds Think Alike',\n",
    "'GR8':'Great!',\n",
    "'G9':'Genius',\n",
    "'IC':'I See',\n",
    "'ICQ':'I Seek you (also a chat program)',\n",
    "'ILU':'ILU: I Love You',\n",
    "'IMHO':'In My Honest/Humble Opinion',\n",
    "'IMO':'In My Opinion',\n",
    "'IOW':'In Other Words',\n",
    "'IRL':'In Real Life',\n",
    "'KISS':'Keep It Simple, Stupid',\n",
    "'LDR':'Long Distance Relationship',\n",
    "'LMAO':'Laugh My A.. Off',\n",
    "'LOL':'Laughing Out Loud',\n",
    "'LTNS':'Long Time No See',\n",
    "'L8R':'Later',\n",
    "'MTE':'My Thoughts Exactly',\n",
    "'M8':'Mate',\n",
    "'NRN':'No Reply Necessary',\n",
    "'OIC':'Oh I See',\n",
    "'PITA':'Pain In The A..',\n",
    "'PRT':'Party',\n",
    "'PRW':'Parents Are Watching',\n",
    "'QPSA?':'Que Pasa?',\n",
    "'ROFL':'Rolling On The Floor Laughing',\n",
    "'ROFLOL':'Rolling On The Floor Laughing Out Loud',\n",
    "'ROTFLMAO':'Rolling On The Floor Laughing My A.. Off',\n",
    "'SK8':'Skate',\n",
    "'STATS':'Your sex and age',\n",
    "'ASL':'Age, Sex, Location',\n",
    "'THX':'Thank You',\n",
    "'TTFN':'Ta:Ta For Now!',\n",
    "'TTYL':'Talk To You Later',\n",
    "'U':'You',\n",
    "'U2':'You Too',\n",
    "'U4E':'Yours For Ever',\n",
    "'WB':'Welcome Back',\n",
    "'WTF':'What The F...',\n",
    "'WTG':'Way To Go!',\n",
    "'WUF':'Where Are You From?',\n",
    "'W8':'Wait...',\n",
    "'7K':'Sick::D Laugher',\n",
    "'TFW' : 'That feeling when. TFW internet slang often goes in a caption to an image.',\n",
    "'MFW' : 'My face when',\n",
    "'MRW' : 'My reaction when',\n",
    "'IFYP' : 'I feel your pain',\n",
    "'LOL' : 'Laughing out loud',\n",
    "'TNTL' : 'Trying not to laugh',\n",
    "'JK' : 'Just kidding',\n",
    "'IDC' : 'I donâ€™t care',\n",
    "'ILY' : 'I love you',\n",
    "'IMU' : 'I miss you',\n",
    "'ADIH' : 'Another day in hell',\n",
    "'IDC' : 'I donâ€™t care',\n",
    "'ZZZ' : 'Sleeping, bored, tired',\n",
    "'WYWH' : 'Wish you were here',\n",
    "'TIME' : 'Tears in my eyes',\n",
    "'BAE' : 'Before anyone else',\n",
    "'FIMH' : 'Forever in my heart',\n",
    "'BSAAW' : 'Big smile and a wink',\n",
    "'BWL' : 'Bursting with laughter',\n",
    "'LMAO' : 'Laughing my a** off',\n",
    "'BFF': 'Best friends forever',\n",
    "'CSL': 'Canâ€™t stop laughing'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "600eaa84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AFAIK': 'As Far As I Know',\n",
       " 'AFK': 'Away From Keyboard',\n",
       " 'ASAP': 'As Soon As Possible',\n",
       " 'ATK': 'At The Keyboard',\n",
       " 'ATM': 'At The Moment',\n",
       " 'A3': 'Anytime, Anywhere, Anyplace',\n",
       " 'BAK': 'Back At Keyboard',\n",
       " 'BBL': 'Be Back Later',\n",
       " 'BBS': 'Be Back Soon',\n",
       " 'BFN': 'Bye For Now',\n",
       " 'B4N': 'Bye For Now',\n",
       " 'BRB': 'Be Right Back',\n",
       " 'BRT': 'Be Right There',\n",
       " 'BTW': 'By The Way',\n",
       " 'B4': 'Before',\n",
       " 'CU': 'See You',\n",
       " 'CUL8R': 'See You Later',\n",
       " 'CYA': 'See You',\n",
       " 'FAQ': 'Frequently Asked Questions',\n",
       " 'FC': 'Fingers Crossed',\n",
       " 'FWIW': 'For What Its Worth',\n",
       " 'FYI': 'For Your Information',\n",
       " 'GAL': 'Get A Life',\n",
       " 'GG': 'Good Game',\n",
       " 'GN': 'Good Night',\n",
       " 'GMTA': 'Great Minds Think Alike',\n",
       " 'GR8': 'Great!',\n",
       " 'G9': 'Genius',\n",
       " 'IC': 'I See',\n",
       " 'ICQ': 'I Seek you (also a chat program)',\n",
       " 'ILU': 'ILU: I Love You',\n",
       " 'IMHO': 'In My Honest/Humble Opinion',\n",
       " 'IMO': 'In My Opinion',\n",
       " 'IOW': 'In Other Words',\n",
       " 'IRL': 'In Real Life',\n",
       " 'KISS': 'Keep It Simple, Stupid',\n",
       " 'LDR': 'Long Distance Relationship',\n",
       " 'LMAO': 'Laughing my a** off',\n",
       " 'LOL': 'Laughing out loud',\n",
       " 'LTNS': 'Long Time No See',\n",
       " 'L8R': 'Later',\n",
       " 'MTE': 'My Thoughts Exactly',\n",
       " 'M8': 'Mate',\n",
       " 'NRN': 'No Reply Necessary',\n",
       " 'OIC': 'Oh I See',\n",
       " 'PITA': 'Pain In The A..',\n",
       " 'PRT': 'Party',\n",
       " 'PRW': 'Parents Are Watching',\n",
       " 'QPSA?': 'Que Pasa?',\n",
       " 'ROFL': 'Rolling On The Floor Laughing',\n",
       " 'ROFLOL': 'Rolling On The Floor Laughing Out Loud',\n",
       " 'ROTFLMAO': 'Rolling On The Floor Laughing My A.. Off',\n",
       " 'SK8': 'Skate',\n",
       " 'STATS': 'Your sex and age',\n",
       " 'ASL': 'Age, Sex, Location',\n",
       " 'THX': 'Thank You',\n",
       " 'TTFN': 'Ta:Ta For Now!',\n",
       " 'TTYL': 'Talk To You Later',\n",
       " 'U': 'You',\n",
       " 'U2': 'You Too',\n",
       " 'U4E': 'Yours For Ever',\n",
       " 'WB': 'Welcome Back',\n",
       " 'WTF': 'What The F...',\n",
       " 'WTG': 'Way To Go!',\n",
       " 'WUF': 'Where Are You From?',\n",
       " 'W8': 'Wait...',\n",
       " '7K': 'Sick::D Laugher',\n",
       " 'TFW': 'That feeling when. TFW internet slang often goes in a caption to an image.',\n",
       " 'MFW': 'My face when',\n",
       " 'MRW': 'My reaction when',\n",
       " 'IFYP': 'I feel your pain',\n",
       " 'TNTL': 'Trying not to laugh',\n",
       " 'JK': 'Just kidding',\n",
       " 'IDC': 'I donâ€™t care',\n",
       " 'ILY': 'I love you',\n",
       " 'IMU': 'I miss you',\n",
       " 'ADIH': 'Another day in hell',\n",
       " 'ZZZ': 'Sleeping, bored, tired',\n",
       " 'WYWH': 'Wish you were here',\n",
       " 'TIME': 'Tears in my eyes',\n",
       " 'BAE': 'Before anyone else',\n",
       " 'FIMH': 'Forever in my heart',\n",
       " 'BSAAW': 'Big smile and a wink',\n",
       " 'BWL': 'Bursting with laughter',\n",
       " 'BFF': 'Best friends forever',\n",
       " 'CSL': 'Canâ€™t stop laughing'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cde8af5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_conversion(text):\n",
    "    new_text = []\n",
    "    for w in text.split():\n",
    "        if w.upper() in chat_words:\n",
    "            new_text.append(chat_words[w.upper()])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "defae0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Good Night'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversion(\"Hello GN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf12f13",
   "metadata": {},
   "source": [
    "# 6)Speeling Mistake:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edfd6142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d754b587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello my name is clean'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incoorect_txt = \"Hello my nmae is chetan\"\n",
    "textBlb = TextBlob(incoorect_txt)\n",
    "textBlb.correct().string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82c6d92",
   "metadata": {},
   "source": [
    "# 7)Remove Stop Words:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e43e648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "926bbbb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "545bc432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    new_text = []\n",
    "    for word in text.split():\n",
    "        if word in stopwords.words('english'):\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    x = new_text[:]\n",
    "    new_text.clear()\n",
    "    return \" \".join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee6c5a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello  fine   '"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(\"hello is fine and the all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36f2190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##df[\"review\"] = df[\"review\"].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ebf27c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97659d35",
   "metadata": {},
   "source": [
    "# 8)Handling Emoji:-"
   ]
  },
  {
   "cell_type": "raw",
   "id": "07016dc8",
   "metadata": {},
   "source": [
    "i)Remove Emoji:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7823331e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\" \n",
    "                               u\"\\U0001F600-\\U0001F64F\"  #emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  #symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  #transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  #flags(ios)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"  #emoticons\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c06e03f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello '"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_emoji(\"Hello ðŸ˜¡ðŸ˜€ðŸ‘†âš½\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ff27bf91",
   "metadata": {},
   "source": [
    "ii)manage emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74b17de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello :pouting_face::grinning_face::backhand_index_pointing_up::soccer_ball:\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "print(emoji.demojize(\"Hello ðŸ˜¡ðŸ˜€ðŸ‘†âš½\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37beeff0",
   "metadata": {},
   "source": [
    "# Word Tokenization Using the split function:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b43f655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'Pune']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"I am going to Pune\"\n",
    "sent.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0453b84",
   "metadata": {},
   "source": [
    "# Sentence Tokenization Using the split function:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b86a875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am going to Pune', 'I will stay for 3 days']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"I am going to Pune.I will stay for 3 days\"\n",
    "sent.split(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12298e8",
   "metadata": {},
   "source": [
    "# Word Tokenization Using the Regular Expression:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7d388d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'Pune']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "sent = \"I am going to Pune!\"\n",
    "tokens = re.findall(\"[\\w']+\",sent)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "315d4fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem Ipsum is simply dummy text of the printing and typesetting industry',\n",
       " \"Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book.\"]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book.\"\"\"\n",
    "sentence = re.compile('[.!?] ').split(text)\n",
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3df8242",
   "metadata": {},
   "source": [
    "# Word Tokenization Using NLTK:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ce2d17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "45cae5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'pune', '!']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"I am going to pune!\"\n",
    "word_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14e4e659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem Ipsum is simply dummy text of the printing and typesetting industry.',\n",
       " \"Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book.\"]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book.\"\"\"\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55ec6962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'have', 'a', 'Ph.D', 'in', 'A.I']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"I have a Ph.D in A.I\"\n",
    "word_tokenize(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b049d2",
   "metadata": {},
   "source": [
    "# Stemming:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9672d08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "49d57094",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5636058c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'love love lover'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"loving loved lover\"\n",
    "stem_words(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "472e82ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He',\n",
       " 'was',\n",
       " 'running',\n",
       " 'and',\n",
       " 'eating',\n",
       " 'at',\n",
       " 'same',\n",
       " 'time',\n",
       " 'He',\n",
       " 'has',\n",
       " 'bad',\n",
       " 'habbit',\n",
       " 'of',\n",
       " 'swimming',\n",
       " 'after',\n",
       " 'playing',\n",
       " 'long',\n",
       " 'hours',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Sun']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "sent = \"He was running and eating at same time. He has bad habbit of swimming after playing long hours in the Sun.\"\n",
    "punc = \"?:!.,;\"\n",
    "sent_words = nltk.word_tokenize(sent)\n",
    "for word in sent_words:\n",
    "    if word in punc:\n",
    "        sent_words.remove(word)\n",
    "sent_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f72499f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He He\n",
      "was be\n",
      "running run\n",
      "and and\n",
      "eating eat\n",
      "at at\n",
      "same same\n",
      "time time\n",
      "He He\n",
      "has have\n",
      "bad bad\n",
      "habbit habbit\n",
      "of of\n",
      "swimming swim\n",
      "after after\n",
      "playing play\n",
      "long long\n",
      "hours hours\n",
      "in in\n",
      "the the\n",
      "Sun Sun\n"
     ]
    }
   ],
   "source": [
    "for word in sent_words:\n",
    "    print(word,wordnet_lemmatizer.lemmatize(word,pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabc0d89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
